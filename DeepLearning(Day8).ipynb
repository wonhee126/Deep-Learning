{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNO1jxdFxnHw",
    "outputId": "4fcb924d-b9d0-4957-b3cf-4ab99c6ca9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (5.4.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from konlpy) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9s2U1-zym29",
    "outputId": "899eb702-bbc0-40fc-f735-477408258411"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 13.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "m-kxekL-ykOO",
    "outputId": "b0ac86eb-fc3b-4253-a54d-f64fd2f7b044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp38-cp38-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\juwonhee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/24.0 MB 8.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.2/24.0 MB 10.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.0/24.0 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.7/24.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.3/24.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 13.9/24.0 MB 11.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.5/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.9/24.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.2/24.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.3 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Gh41qONxfw1",
    "outputId": "664e7725-5e3c-401c-8be8-a5c56b2e34bc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "oSuk1d9Cxohn",
    "outputId": "b2bed1bc-c96c-418d-ed93-893c9d66493e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.\" # 토큰화와 전처리가 전혀 되어 있지 않은 텍트트\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규 표현식을 반영하여 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VG-H_0dbxtCK",
    "outputId": "935a707e-290e-435d-a0d9-13186a3621a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임금님 귀는 당나귀 귀 임금님 귀는 당나귀 귀 실컷 소리치고 나니 속이 확 뚫려 살 것 같았어\n"
     ]
    }
   ],
   "source": [
    "reg = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\") # 자음, 모음, 한글 글자, 공백 제외 문자를 남기고 나머지 제거\n",
    "text = reg.sub('', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토큰화 KoNLPy Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhtYLtRqxuUZ",
    "outputId": "e3e75d2d-3268-458c-8304-7dedeb0f96ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['임금님', '귀', '는', '당나귀', '귀', '임금님', '귀', '는', '당나귀', '귀', '실컷', '소리', '치고', '나니', '속이', '확', '뚫려', '살', '것', '같았어']\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "tokens = okt.morphs(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RE4h2XJ7xwZ_",
    "outputId": "27df53f5-bbdf-4872-8ad7-4c651abc789b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'귀': 4, '임금님': 2, '는': 2, '당나귀': 2, '실컷': 1, '소리': 1, '치고': 1, '나니': 1, '속이': 1, '확': 1, '뚫려': 1, '살': 1, '것': 1, '같았어': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(tokens)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyTXpAF6xy0z",
    "outputId": "f7c65b46-06d2-4a49-ad5d-46a0e20da0ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['임금님']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asQpU9Wgxz1D",
    "outputId": "0253e5de-9d9e-4a1d-f819-2946a67c5c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('귀', 4), ('임금님', 2), ('는', 2), ('당나귀', 2), ('실컷', 1)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bg0pBmxx1Up",
    "outputId": "9b67e212-7276-4f76-d20b-9d75e8f6d827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'귀': 1, '임금님': 2, '는': 3, '당나귀': 4, '실컷': 5}\n"
     ]
    }
   ],
   "source": [
    "word2idx={word[0] : index+1 for index, word in enumerate(vocab)}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원-핫 벡터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dW56hIcsyNB6",
    "outputId": "5c566477-1a2f-470a-eebb-b162f02ddafa"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "       one_hot_vector = [0]*(len(word2index))\n",
    "       index = word2index[word]\n",
    "       one_hot_vector[index-1] = 1\n",
    "       return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HguLlZ58yRlO",
    "outputId": "ca42504a-5a9e-48d1-c51d-0ba2b494b738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"임금님\", word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스를 통한 원-핫 인코딩 one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCxcEa94ySQA",
    "outputId": "e36fb263-0d0b-401e-9923-495bc3d99ff2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVYFYnbXyTRb",
    "outputId": "d1ce9e7f-e7e2-4436-e030-a00cd53736aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['강아지', '고양이', '강아지'], ['애교', '고양이'], ['컴퓨터', '노트북']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [['강아지', '고양이', '강아지'],['애교', '고양이'], ['컴퓨터', '노트북']]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsmAvD5wyVv1",
    "outputId": "ef832ffc-4415-451f-c6d5-06b18d2db1a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'강아지': 1, '고양이': 2, '애교': 3, '컴퓨터': 4, '노트북': 5}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "print(t.word_index) # 각 단어에 대한 인코딩 결과 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVyCuTspyXUY",
    "outputId": "423058c0-0499-4f60-f150-c1a20d72ff72"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaKmcGEMybuG",
    "outputId": "790aecab-3135-49e5-856b-5b0d70db8b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "sub_text = ['강아지', '고양이', '강아지', '컴퓨터']\n",
    "encoded = t.texts_to_sequences([sub_text])\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원-핫 벡터의 시퀀스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKaAztTCyc10",
    "outputId": "eb7281e9-609b-4802-d3bf-39a0f6143adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical(encoded, num_classes = vocab_size)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영어 Word2Vec 실습과 OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egjUWoRmyd8I",
    "outputId": "671e4125-3701-4fea-824b-f14b7c0e8290"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to\n",
      "[nltk_data]     C:\\Users\\juwonhee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\abc.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\juwonhee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "\n",
    "## 이부분 punkt 대신 punkt_tab을 이용\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tH055v5Yy1J3",
    "outputId": "084c28bc-e7a4-44ad-a0d2-4730a2a89f4d"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import abc\n",
    "corpus = abc.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hb6cSjpzb8p",
    "outputId": "e1dc00b8-a6dd-4a1f-b362-622e09707839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', 'The', 'Prime', 'Minister', 'has', 'denied', 'he', 'knew', 'AWB', 'was', 'paying', 'kickbacks', 'to', 'Iraq', 'despite', 'writing', 'to', 'the', 'wheat', 'exporter', 'asking', 'to', 'be', 'kept', 'fully', 'informed', 'on', 'Iraq', 'wheat', 'sales', '.'], ['Letters', 'from', 'John', 'Howard', 'and', 'Deputy', 'Prime', 'Minister', 'Mark', 'Vaile', 'to', 'AWB', 'have', 'been', 'released', 'by', 'the', 'Cole', 'inquiry', 'into', 'the', 'oil', 'for', 'food', 'program', '.'], ['In', 'one', 'of', 'the', 'letters', 'Mr', 'Howard', 'asks', 'AWB', 'managing', 'director', 'Andrew', 'Lindberg', 'to', 'remain', 'in', 'close', 'contact', 'with', 'the', 'Government', 'on', 'Iraq', 'wheat', 'sales', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKFTFco3zdBq",
    "outputId": "ea5b5ef3-5f1e-46a1-89fe-8daf9a5e5a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스의 크기 : 29059\n"
     ]
    }
   ],
   "source": [
    "print('코퍼스의 크기 :',len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec 훈련\n",
    "- vector size = 학습 후 임베딩 벡터의 차원\n",
    "- window = 컨텍스트 윈도우 크기\n",
    "- min_count = 단어 최소 빈도수 제한 (빈도가 적은 단어들은 학습하지 않아요.)\n",
    "- workers = 학습을 위한 프로세스 수\n",
    "- sg = 0은 CBoW, 1은 Skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8rns_DfzeB4",
    "outputId": "5716696a-b2b9-4ef5-b162-2b0bb7e3a074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = corpus, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 어떤 학습을 마친걸까?  \n",
    "단어를 벡터(숫자)로 표현하는 방법을 학습했다는 의미  \n",
    "sg=0 이기 때문에 CBow 방법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec는 입력한 단어에 대해서 가장 코사인 유사도가 높은 단어들을 출력하는\n",
    "-> model.wv.most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hK4SvvQz6mS",
    "outputId": "c170dc8b-7b75-40a0-cab0-c48bc7ca3d3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233420491218567), ('skull', 0.9110078811645508), ('Bang', 0.9056522250175476), ('asteroid', 0.9051969051361084), ('third', 0.9020065665245056), ('baby', 0.8994149565696716), ('dog', 0.8985928893089294), ('bought', 0.8975393772125244), ('rally', 0.8912544846534729), ('disc', 0.8888999223709106)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2zvf2OPz9Bj",
    "outputId": "799348f1-7e6d-487a-95a7-173cc3184666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델  load 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model.wv.save_word2vec_format('./w2v')\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"./w2v\")\n",
    "print(\"모델  load 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bB2SmbNz0E-n",
    "outputId": "44212af1-ceb0-45fe-f085-b4e54f4c0e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233420491218567), ('skull', 0.9110078811645508), ('Bang', 0.9056522250175476), ('asteroid', 0.9051969051361084), ('third', 0.9020065665245056), ('baby', 0.8994149565696716), ('dog', 0.8985928893089294), ('bought', 0.8975393772125244), ('rally', 0.8912544846534729), ('disc', 0.8888999223709106)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result) # (유사단어, 유사도 점수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec의 OOV 문제 (Out of Vocabuary)\n",
    "Bag of Words 학습 과정에서 언급되었던 문제인, 미등록 단어 문제와  \n",
    "오타 단어는 에러를 발생시킨다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "8XmMQx4Q0Ggd",
    "outputId": "092195f8-e857-4932-d885-727d4bf22474"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'overacting' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 에러나는 코드가 맞음\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moveracting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemorry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    844\u001b[0m ]\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'overacting' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# 에러나는 코드가 맞음\n",
    "loaded_model.most_similar('overacting')\n",
    "loaded_model.most_similar('memorry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 벡터의 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 Word2Vec 모델이 단어들을 100차원의 숫자 벡터로 변환  \n",
    "그 숫자 벡터들이 실제로 어떤 의미를 가지고, 어떻게 배치되어 있는지 시각화하기 위해  \n",
    "임베딩 프로젝터를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4hCGUCg0MFG",
    "outputId": "fadba53e-6225-4705-ea3e-def68ff73066"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 12:50:09,426 - word2vec2tensor - INFO - running C:\\Users\\juwonhee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input ./w2v --output ./w2v\n",
      "2025-06-17 12:50:09,426 - keyedvectors - INFO - loading projection weights from ./w2v\n",
      "2025-06-17 12:50:09,983 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (10363, 100) matrix of type float32 from ./w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-06-17T12:50:09.983717', 'gensim': '4.3.3', 'python': '3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-06-17 12:50:10,628 - word2vec2tensor - INFO - 2D tensor file saved to ./w2v_tensor.tsv\n",
      "2025-06-17 12:50:10,628 - word2vec2tensor - INFO - Tensor metadata file saved to ./w2v_metadata.tsv\n",
      "2025-06-17 12:50:10,628 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "# word2vec 모델 메타정보 및 텐서 내보내기\n",
    "!python -m gensim.scripts.word2vec2tensor --input ./w2v --output ./w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText\n",
    "Word2Vec은 더 이상 깨질 수 없는 단위로 단어를 구분하는 반면,  \n",
    "FastText는 단어 내부의 내부 단어를 학습한다는 아이디어를 가지고 있다.  \n",
    "네거티브 샘플링을 사용하여 학습한다.  \n",
    "다만, Word2Vec과 다른 점은 학습 과정에서 중심 단어에 속한 문자 단위 단어 벡터들을 모두 업데이트한다.\n",
    "- OOV와 오타에 강건하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCwipTr30zC_",
    "outputId": "fff5d9a6-e075-4bb2-d062-4784a08ff5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = FastText(corpus, window=5, min_count=5, workers=4, sg=1)\n",
    "print(\"FastText 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3Cx0B2w1E-B",
    "outputId": "7cfc442c-eaf5-4a20-aff2-27c4fcef0e69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fluctuating', 0.9377561211585999),\n",
       " ('resolving', 0.9375224709510803),\n",
       " ('emptying', 0.9363172650337219),\n",
       " ('extracting', 0.9336783289909363),\n",
       " ('malting', 0.9330613613128662),\n",
       " ('mounting', 0.9304724335670471),\n",
       " ('shooting', 0.9295411109924316),\n",
       " ('lifting', 0.9291247725486755),\n",
       " ('declining', 0.928656280040741),\n",
       " ('overwhelming', 0.9271591901779175)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('overacting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Su2Ceij1GT7",
    "outputId": "f7bdd552-8121-4f93-a9e0-d60a5ebf8373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memory', 0.9466140270233154),\n",
       " ('musical', 0.8680832386016846),\n",
       " ('mechanisms', 0.8637781739234924),\n",
       " ('mechanism', 0.8612226247787476),\n",
       " ('basic', 0.8582766056060791),\n",
       " ('mechanical', 0.8552515506744385),\n",
       " ('imagine', 0.8516234755516052),\n",
       " ('technical', 0.8439446091651917),\n",
       " ('intelligence', 0.839522123336792),\n",
       " ('visual', 0.8367835283279419)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('memoryy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memoryy 와 가장 유사한 단어로 memory가 출력된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe\n",
    "- 카운트 기반(DTM)\n",
    "- 예측 기반(Word2Vec와 같은 방법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AB2hz_s1Hrl",
    "outputId": "ea69f5fd-46d7-405e-e2da-a8a8917238a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9218006134033203),\n",
       " ('dogs', 0.8513158559799194),\n",
       " ('horse', 0.7907583117485046),\n",
       " ('puppy', 0.7754921317100525),\n",
       " ('pet', 0.7724707722663879),\n",
       " ('rabbit', 0.7720813751220703),\n",
       " ('pig', 0.7490062117576599),\n",
       " ('snake', 0.7399188280105591),\n",
       " ('baby', 0.7395570278167725),\n",
       " ('bite', 0.7387937307357788)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "glove_model = api.load(\"glove-wiki-gigaword-50\")  # glove vectors 다운로드\n",
    "glove_model.most_similar(\"dog\")  # 'dog'과 비슷한 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beg3s-wD1Kum",
    "outputId": "dd585fdb-9e83-4e6b-b710-0e1c93762ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impudence', 0.7842012643814087),\n",
       " ('puerile', 0.7816032767295837),\n",
       " ('winningly', 0.7644237279891968),\n",
       " ('grossness', 0.7576098442077637),\n",
       " ('deconstructions', 0.748936653137207),\n",
       " ('over-the-top', 0.7460805177688599),\n",
       " ('buffoonery', 0.746045708656311),\n",
       " ('impetuosity', 0.7415392994880676),\n",
       " ('sophomoric', 0.736961841583252),\n",
       " ('zaniness', 0.7353197336196899)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('overacting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "noIb3XIR1Lmf",
    "outputId": "28742da6-9549-4d61-93dc-a6dba6ee6847"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'memoryy' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m glove_model\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemoryy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_vector(keys, weight, pre_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, post_normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    844\u001b[0m ]\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[1;32m~\\Anaconda3\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'memoryy' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "glove_model.most_similar('memoryy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe는 Word2Vec와 같이 OOV 문제를 가지고 있어서 오타를 인식하지 못한다.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
